import torch
import torch.nn as nn


class cnnmodel(nn.Module):
    """"""
    def __init__(self):
        super().__init__()
        #创建cnn卷积层
        self.CNN=nn.Sequential(nn.Conv2d(in_channels=3,out_channels=16,kernel_size=7,padding=3),
                    nn.BatchNorm2d(16),nn.ReLU(),
                    nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,padding=1),
                    nn.BatchNorm2d(32),nn.ReLU(),nn.MaxPool2d(kernel_size=2,stride=2),
                    nn.Conv2d(in_channels=32,out_channels=48,kernel_size=3,padding=1),
                    nn.BatchNorm2d(48),nn.ReLU(),nn.MaxPool2d(kernel_size=2,stride=2),
                    nn.Conv2d(in_channels=48,out_channels=64,kernel_size=3,padding=1),
                    nn.BatchNorm2d(64),nn.ReLU(),nn.MaxPool2d(kernel_size=2,stride=2),
                    nn.Conv2d(in_channels=64,out_channels=80,kernel_size=3,padding=1),
                    nn.AdaptiveAvgPool2d((32,32)))
        #创建线性层
        self.Linear=nn.Sequential(nn.Linear(80*32*32,512),
                      nn.ReLU(),
                      nn.Dropout(p=0.5),
                      nn.Linear(512,10))
        self.initweight()
        

    def initweight(self):
        for m in self.modules():
            if isinstance(m,nn.Linear):
                """"""
                nn.init.xavier_normal_(m.weight)
                nn.init.zeros_(m.bias)
            elif isinstance(m,nn.Conv2d):
                nn.init.xavier_normal_(m.weight)
                nn.init.zeros_(m.bias)

    def forward(self,x):
        x=self.CNN(x)
        x=x.view(x.size(0),-1)
        x=self.Linear(x)
        return x   

